[chapter]
[[getting-started]]
= 快速开始

这份指南将帮助新人学会如何: 

* 在测试环境下安装和运行 {es}
* 在 {es} 中新增数据
* 进行数据的简单查询和排序
* 进行数据的复杂查询以及从非结构化结果中提取特定字段数据

[discrete]
[[run-elasticsearch]]
=== 运行 {es}

设置 {es} 最简单的方法是使用 {ecloud} 上的 {ess} 创建托管部署. 
如果你更喜欢在你的测试环境使用, 可以在 Docker 中安装运行 {es} .

include::{es-repo-dir}/tab-widgets/quick-start-install-widget.asciidoc[]

[discrete]
[[send-requests-to-elasticsearch]]
=== 向 {es} 发送请求

你可以通过 REST API 来向 {es} 发送数据或其他请求. 
任何可以发送 HTTP 请求的客户端 (例如: https://curl.se[curl]) 都可以被用来和 {es} 进行交互. 
当然, {kib} 的控制台也可以. 

include::{es-repo-dir}/tab-widgets/api-call-widget.asciidoc[]

[discrete]
[[add-data]]
=== 新增数据

你将以"文档" (内部为JSON对象结构) 形式来新增数据. {es} 会将这些文档存储为可索引状态. 

对于"时间序列" (例如: 日志、度量值) 数据, 通常的做法是把这些"文档"添加到由多个 自生成 的"次级索引"组成的数据流中. 

数据流需要与其名字相匹配的索引模板. {es} 使用这个模板来配置数据流的"次级索引". 提交到数据流的"文档"必须有 `@timestamp` 字段.

[discrete]
[[add-single-document]]
==== 新增单个"文档"

提交如下的索引请求会向 `logs-my_app-default` 数据流新增一个单条的日志条目, 
如果 `logs-my_app-default` 数据流不存在, 这个请求将会参考内置 `logs-*-*` 索引模板来自动新增一个数据流. 

[source,console]
----
POST logs-my_app-default/_doc
{
  "@timestamp": "2099-05-06T16:21:15.000Z",
  "event": {
    "original": "192.0.2.42 - - [06/May/2099:16:21:15 +0000] \"GET /images/bg.jpg HTTP/1.0\" 200 24736"
  }
}
----
// TEST[s/_doc/_doc?refresh=wait_for/]

响应会包含 {es} 自生成的"文档"元数据: 

* `_index` : 包含"文档"的"次级索引". {es} 会自生成"次级索引"的名称. 
* `_id` : 文档的唯一索引. 

[source,console-result]
----
{
  "_index": ".ds-logs-my_app-default-2099-05-06-000001",
  "_id": "gl5MJXMBMk1dGnErnBW8",
  "_version": 1,
  "result": "created",
  "_shards": {
    "total": 2,
    "successful": 1,
    "failed": 0
  },
  "_seq_no": 0,
  "_primary_term": 1
}
----
// TESTRESPONSE[s/"_index": ".ds-logs-my_app-default-2099-05-06-000001"/"_index": $body._index/]
// TESTRESPONSE[s/"_id": "gl5MJXMBMk1dGnErnBW8"/"_id": $body._id/]

[discrete]
[[add-multiple-documents]]
==== 新增多个"文档" 

在一条请求中访问 `_bulk` 端点可以批量新增多个"文档". 
批量数据必须是 NDJSON 结构 (http://ndjson.org/[换行分隔JSON]), 数据 (包括最后一行数据) 的每行必须用换行符 (`\n`) 结尾. 

[source,console]
----
PUT logs-my_app-default/_bulk
{ "create": { } }
{ "@timestamp": "2099-05-07T16:24:32.000Z", "event": { "original": "192.0.2.242 - - [07/May/2020:16:24:32 -0500] \"GET /images/hm_nbg.jpg HTTP/1.0\" 304 0" } }
{ "create": { } }
{ "@timestamp": "2099-05-08T16:25:42.000Z", "event": { "original": "192.0.2.255 - - [08/May/2099:16:25:42 +0000] \"GET /favicon.ico HTTP/1.0\" 200 3638" } }
----
// TEST[continued]
// TEST[s/_bulk/_bulk?refresh=wait_for/]

[discrete]
[[qs-search-data]]
=== 查询数据

已索引"文档" 可用于近实时搜索. 
如下的查询会匹配到所有 `logs-my_app-default` 数据流中、通过 `@timestamp` 降序排列的日志条目. 

[source,console]
----
GET logs-my_app-default/_search
{
  "query": {
    "match_all": { }
  },
  "sort": [
    {
      "@timestamp": "desc"
    }
  ]
}
----
// TEST[continued]

默认条件下, `hits` 响应部分包含前10条匹配查询条件的"文档". 
每个查询结果的 `_source` 包含索引期间提交的原始JSON对象. 

[source,console-result]
----
{
  "took": 2,
  "timed_out": false,
  "_shards": {
    "total": 1,
    "successful": 1,
    "skipped": 0,
    "failed": 0
  },
  "hits": {
    "total": {
      "value": 3,
      "relation": "eq"
    },
    "max_score": null,
    "hits": [
      {
        "_index": ".ds-logs-my_app-default-2099-05-06-000001",
        "_id": "PdjWongB9KPnaVm2IyaL",
        "_score": null,
        "_source": {
          "@timestamp": "2099-05-08T16:25:42.000Z",
          "event": {
            "original": "192.0.2.255 - - [08/May/2099:16:25:42 +0000] \"GET /favicon.ico HTTP/1.0\" 200 3638"
          }
        },
        "sort": [
          4081940742000
        ]
      },
      ...
    ]
  }
}
----
// TESTRESPONSE[s/"took": 2/"took": $body.took/]
// TESTRESPONSE[s/"_index": ".ds-logs-my_app-default-2099-05-06-000001"/"_index": $body.hits.hits.0._index/]
// TESTRESPONSE[s/"_id": "PdjWongB9KPnaVm2IyaL"/"_id": $body.hits.hits.0._id/]
// TESTRESPONSE[s/\.\.\./$body.hits.hits.1,$body.hits.hits.2/]

[discrete]
[[get-specific-fields]]
==== 查询特定字段数据

对于大型"文档", 解析完整的 `_source` 数据是不明智的. 可以通过设置 `_source` 参数为 `false` 来把它从响应结果中排除, 并通过添加 `fields` 请求参数来检索你需要的字段. 

[source,console]
----
GET logs-my_app-default/_search
{
  "query": {
    "match_all": { }
  },
  "fields": [
    "@timestamp"
  ],
  "_source": false,
  "sort": [
    {
      "@timestamp": "desc"
    }
  ]
}
----
// TEST[continued]
// TEST[s/_search/_search?filter_path=hits.hits&size=1/]

响应以展开数组的形式包含每个查询结果的 `fields` 值

[source,console-result]
----
{
  ...
  "hits": {
    ...
    "hits": [
      {
        "_index": ".ds-logs-my_app-default-2099-05-06-000001",
        "_id": "PdjWongB9KPnaVm2IyaL",
        "_score": null,
        "fields": {
          "@timestamp": [
            "2099-05-08T16:25:42.000Z"
          ]
        },
        "sort": [
          4081940742000
        ]
      },
      ...
    ]
  }
}
----
// TESTRESPONSE[s/\.\.\.//]
// TESTRESPONSE[s/"_index": ".ds-logs-my_app-default-2099-05-06-000001"/"_index": $body.hits.hits.0._index/]
// TESTRESPONSE[s/"_id": "PdjWongB9KPnaVm2IyaL"/"_id": $body.hits.hits.0._id/]
// TESTRESPONSE[s/4081940742000\n        \]\n      \},\n/4081940742000\]}/]

[discrete]
[[search-date-range]]
==== 以日期等范围为条件查询

使用 `range` 作为 `query` 的查询参数来检索指定时间或IP范围内的数据

[source,console]
----
GET logs-my_app-default/_search
{
  "query": {
    "range": {
      "@timestamp": {
        "gte": "2099-05-05",
        "lt": "2099-05-08"
      }
    }
  },
  "fields": [
    "@timestamp"
  ],
  "_source": false,
  "sort": [
    {
      "@timestamp": "desc"
    }
  ]
}
----
// TEST[continued]

你可以使用日期表达式来定义相对时间范围. 如下请求中的 `query` 查询参数将查询过去一天的数据, 预计将不会匹配到任何 `logs-my_app-default` 数据流中的日志条目. 

[source,console]
----
GET logs-my_app-default/_search
{
  "query": {
    "range": {
      "@timestamp": {
        "gte": "now-1d/d",
        "lt": "now/d"
      }
    }
  },
  "fields": [
    "@timestamp"
  ],
  "_source": false,
  "sort": [
    {
      "@timestamp": "desc"
    }
  ]
}
----
// TEST[continued]

[discrete]
[[extract-fields]]
==== 从非结构化内容中提取字段数据

你可以在查询过程中从非结构化内容中提取 <<runtime-search-request,运行时字段>> 数据, 例如日志信息. 

使用如下的查询来从 `event.original` 的运行时结果中提取 `source.ip` 为名的运行时字段数据. 在 `fields` 查询参数中添加 `source.ip` 来将上述查询数据反馈到响应结果中. 

[source,console]
----
GET logs-my_app-default/_search
{
  "runtime_mappings": {
    "source.ip": {
      "type": "ip",
      "script": """
        String sourceip=grok('%{IPORHOST:sourceip} .*').extract(doc[ "event.original" ].value)?.sourceip;
        if (sourceip != null) emit(sourceip);
      """
    }
  },
  "query": {
    "range": {
      "@timestamp": {
        "gte": "2099-05-05",
        "lt": "2099-05-08"
      }
    }
  },
  "fields": [
    "@timestamp",
    "source.ip"
  ],
  "_source": false,
  "sort": [
    {
      "@timestamp": "desc"
    }
  ]
}
----
// TEST[continued]

[discrete]
[[combine-queries]]
==== 组合查询

你可以使用 `bool` 作为 `query` 查询参数来组合复杂的查询参数条件. 
如下的查询会组合两个 `range` 查询参数, 一个限制 `@timestamp`, 一个限制 `source.ip` 的运行时字段. 


[source,console]
----
GET logs-my_app-default/_search
{
  "runtime_mappings": {
    "source.ip": {
      "type": "ip",
      "script": """
        String sourceip=grok('%{IPORHOST:sourceip} .*').extract(doc[ "event.original" ].value)?.sourceip;
        if (sourceip != null) emit(sourceip);
      """
    }
  },
  "query": {
    "bool": {
      "filter": [
        {
          "range": {
            "@timestamp": {
              "gte": "2099-05-05",
              "lt": "2099-05-08"
            }
          }
        },
        {
          "range": {
            "source.ip": {
              "gte": "192.0.2.0",
              "lte": "192.0.2.240"
            }
          }
        }
      ]
    }
  },
  "fields": [
    "@timestamp",
    "source.ip"
  ],
  "_source": false,
  "sort": [
    {
      "@timestamp": "desc"
    }
  ]
}
----
// TEST[continued]

[discrete]
[[aggregate-data]]
==== 聚合数据 

使用聚合将数据汇总成指标、统计数据或其他分析. 

如下查询使用聚合来使用 `http.response.body.bytes` 运行时字段数据 计算 `average_response_size` . 聚合仅会在匹配 `query` 查询条件的文档结果中生效. 

[source,console]
----
GET logs-my_app-default/_search
{
  "runtime_mappings": {
    "http.response.body.bytes": {
      "type": "long",
      "script": """
        String bytes=grok('%{COMMONAPACHELOG}').extract(doc[ "event.original" ].value)?.bytes;
        if (bytes != null) emit(Integer.parseInt(bytes));
      """
    }
  },
  "aggs": {
    "average_response_size":{
      "avg": {
        "field": "http.response.body.bytes"
      }
    }
  },
  "query": {
    "bool": {
      "filter": [
        {
          "range": {
            "@timestamp": {
              "gte": "2099-05-05",
              "lt": "2099-05-08"
            }
          }
        }
      ]
    }
  },
  "fields": [
    "@timestamp",
    "http.response.body.bytes"
  ],
  "_source": false,
  "sort": [
    {
      "@timestamp": "desc"
    }
  ]
}
----
// TEST[continued]

响应结果中的 `aggregations` 对象包含聚合结果. 

[source,console-result]
----
{
  ...
  "aggregations" : {
    "average_response_size" : {
      "value" : 12368.0
    }
  }
}
----
// TESTRESPONSE[s/\.\.\./"took": "$body.took", "timed_out": false, "_shards": "$body._shards", "hits": "$body.hits",/]

[discrete]
[[explore-more-search-options]]
==== 探索更多查询选项

更多查询选项, 需要给数据流添加更多数据索引, 并查阅 <<common-search-options>>

[discrete]
[[clean-up]]
=== 清理

完成上述测试操作后, 通过如下方法删除你的测试数据和对应的"次级索引"

[source,console]
----
DELETE _data_stream/logs-my_app-default
----
// TEST[continued]

你也可以删除你的测试部署. 

include::{es-repo-dir}/tab-widgets/quick-start-cleanup-widget.asciidoc[]

[discrete]
[[whats-next]]
=== 接下来应该了解什么? 

* 如何通过设置数据分层和 {ilm-init} 来充分利用你的时间序列数据. 请参见 <<use-elasticsearch-for-time-series-data>> .

* 如何使用 {fleet} 和 {agent} 来从你的数据源收集日志和指标并把它们传输给 {es} . 请参见 {observability-guide}/ingest-logs-metrics-uptime.html[使用 {agent} 接收日志、指标和正常运行时间数据] .

* 如何使用 {kib} 来探索、可视化、管理你的 {es} 数据. 请参见 {kibana-ref}/get-started.html[{kib} 快速入门指南] .
